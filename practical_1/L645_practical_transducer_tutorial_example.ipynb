{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BbwgR5UdNkkm"
   },
   "source": [
    "# Transducer implementation in PyTorch\n",
    "\n",
    "*by Loren Lugosch*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yBlJNKsjTtaZ"
   },
   "source": [
    "\n",
    "In this notebook, we will implement a Transducer sequence-to-sequence model for inserting missing vowels into a sentence \n",
    "\n",
    "EX: (\"W wll mplmnt sm cd.\" --> \"We will implement some code.\")\n",
    "*idea: we can change the target sentences to be specific to a domain*\n",
    "\n",
    "\n",
    "Default: (\"Hll, Wrld\" --> \"Hello, World\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q-iHU02C7fAj",
    "outputId": "998d7c43-9796-44bc-a49b-2856eecfbe1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting unidecode\n",
      "  Downloading Unidecode-1.3.4-py3-none-any.whl (235 kB)\n",
      "\u001b[K     |████████████████████████████████| 235 kB 4.3 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: unidecode\n",
      "Successfully installed unidecode-1.3.4\n",
      "\u001b[33mWARNING: You are using pip version 21.1.2; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the '/Users/umeshkumar/PycharmProjects/LING-L645/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'unidecode'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/f7/4pktsxcd2mbdj2rm2c7b_28c0000gp/T/ipykernel_13964/3215111944.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install unidecode'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0munidecode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'unidecode'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import string\n",
    "import numpy as np\n",
    "import itertools\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "!pip install unidecode\n",
    "import unidecode\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DIRECTIONS: Aside from the given training data, find one other open-source data. \n",
    "<15 min>\n",
    "\"\"\"\n",
    "# 1. Default training data.\n",
    "!wget https://raw.githubusercontent.com/lorenlugosch/infer_missing_vowels/master/data/train/war_and_peace.txt\n",
    "!pwd\n",
    "\n",
    "# 2. Find a second training dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CTfRgwxmjv1B"
   },
   "source": [
    "# Building blocks\n",
    "\n",
    "First, we will define the encoder, predictor, and joiner using standard neural nets.\n",
    "\n",
    "<img src=\"https://lorenlugosch.github.io/images/transducer/transducer-model.png\" width=\"25%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B7mLFyUG7kJH"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "RHETORIAL Q: How does changing these numbers affect the performance of the model?\n",
    "In training? In testing? In after-paper performance?\n",
    "\"\"\"\n",
    "NULL_INDEX = 0\n",
    "\n",
    "encoder_dim = 1024\n",
    "predictor_dim = 1024\n",
    "joiner_dim = 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MABMTjrGY4vz"
   },
   "source": [
    "The encoder is any network that can take as input a variable-length sequence: so, RNNs, CNNs, and self-attention/Transformer encoders will all work.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KE7j2T5EY33-"
   },
   "outputs": [],
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "  def __init__(self, num_inputs):\n",
    "    \"\"\"\n",
    "    @num_inputs: the input size/length\n",
    "\n",
    "    DIRECTIONS: complete the variables for the input_size, hidden_size, and bidirectional arguments in self.rnn\n",
    "    <3 min>\n",
    "    \"\"\"\n",
    "    super(Encoder, self).__init__()\n",
    "    self.embed = torch.nn.Embedding(num_inputs, encoder_dim)\n",
    "    self.rnn = torch.nn.GRU(input_size=None, hidden_size=None, num_layers=3, batch_first=True, bidirectional=None, dropout=0.1)\n",
    "    self.linear = torch.nn.Linear(encoder_dim*2, joiner_dim)\n",
    "\n",
    "  def forward(self, x):\n",
    "    out = x\n",
    "    out = self.embed(out)\n",
    "    out = self.rnn(out)[0]\n",
    "    out = self.linear(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BRknN6QRY9-g"
   },
   "source": [
    "The predictor is any _causal_ network (= can't look at the future): in other words, unidirectional RNNs, causal convolutions, or masked self-attention. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hPARF5LmY7-r"
   },
   "outputs": [],
   "source": [
    "class Predictor(torch.nn.Module):\n",
    "  def __init__(self, num_outputs):\n",
    "    \"\"\"\n",
    "    @num_outputs: the output size/length\n",
    "\n",
    "    DIRECTIONS: complete the variables for the input_size and hidden_size arguments in self.rnn\n",
    "                complete the arguments to torch.nn.Linear in self.linear (hint: 2 required)\n",
    "    <3 min>\n",
    "    \"\"\"\n",
    "    super(Predictor, self).__init__()\n",
    "    self.embed = torch.nn.Embedding(num_outputs, predictor_dim)\n",
    "    self.rnn = torch.nn.GRUCell(input_size=None, hidden_size=None)\n",
    "    self.linear = torch.nn.Linear()\n",
    "    \n",
    "    self.initial_state = torch.nn.Parameter(torch.randn(predictor_dim))\n",
    "    self.start_symbol = NULL_INDEX # In the original paper, a vector of 0s is used; just using the null index instead is easier when using an Embedding layer.\n",
    "\n",
    "\n",
    "  def forward_one_step(self, input, previous_state):\n",
    "    \"\"\"\n",
    "    This is a helper function for the inherited forward method (since the input may vary).\n",
    "    @input: decoder input\n",
    "    @previous_state: state before passing the input through the RNN's forward method\n",
    "    \"\"\"\n",
    "    embedding = self.embed(input)\n",
    "    state = self.rnn.forward(embedding, previous_state)\n",
    "    out = self.linear(state)\n",
    "    return out, state\n",
    "\n",
    "\n",
    "  def forward(self, y):\n",
    "    \"\"\"\n",
    "    @y: tensor y\n",
    "\n",
    "    DIRECTIONS: complete the variables for batch_size and U (hint: utilize how y is formatted)\n",
    "                complete the variable in the for loop, i.e. replace the 'None'\n",
    "    <5 min>\n",
    "    \"\"\"\n",
    "    batch_size = None\n",
    "    U = None \n",
    "    outs = []\n",
    "    state = torch.stack([self.initial_state] * batch_size).to(y.device)\n",
    "    for u in range(None): # hint: we want to get the NULL output for the final timestep \n",
    "      if u == 0:\n",
    "        decoder_input = torch.tensor([self.start_symbol] * batch_size).to(y.device)\n",
    "      else:\n",
    "        decoder_input = y[:,u-1]\n",
    "      out, state = self.forward_one_step(decoder_input, state)\n",
    "      outs.append(out)\n",
    "    out = torch.stack(outs, dim=1)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZHPZ3PATZEAW"
   },
   "source": [
    "The joiner is a feedforward network/MLP with one hidden layer applied independently to each $(t,u)$ index.\n",
    "\n",
    "(The linear part of the hidden layer is contained in the encoder and predictor, so we just do the nonlinearity here and then the output layer.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vlzca1orZDLa"
   },
   "outputs": [],
   "source": [
    "class Joiner(torch.nn.Module):\n",
    "  def __init__(self, num_outputs):\n",
    "    \"\"\"\n",
    "    @num_outputs: size of softmax output over all labels\n",
    "    \"\"\"\n",
    "    super(Joiner, self).__init__()\n",
    "    self.linear = torch.nn.Linear(joiner_dim, num_outputs)\n",
    "\n",
    "  def forward(self, encoder_out, predictor_out):\n",
    "    \"\"\"\n",
    "    @encoder_out: \n",
    "    @predictor_out: \n",
    "\n",
    "    DIRECTIONS:    choose and apply a nonlinear function of your choice\n",
    "    RHETORICAL Q:  why do we add nonlinearity in a neural network?\n",
    "    <5 min>\n",
    "    \"\"\"\n",
    "    out = encoder_out + predictor_out\n",
    "    # out = ___ # add nonlinearity here\n",
    "    out = self.linear(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a_-INbhSTApv"
   },
   "source": [
    "# Transducer model + loss function\n",
    "\n",
    "Using the encoder, predictor, and joiner, we will implement the Transducer model and its loss function.\n",
    "\n",
    "<img src=\"https://lorenlugosch.github.io/images/transducer/forward-messages.png\" width=\"25%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bdcKwA_lkzxJ"
   },
   "source": [
    "We can use a simple PyTorch implementation of the loss function, relying on automatic differentiation to give us gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sYSagKi-gHM4"
   },
   "outputs": [],
   "source": [
    "class Transducer(torch.nn.Module):\n",
    "  def __init__(self, num_inputs, num_outputs):\n",
    "    super(Transducer, self).__init__()\n",
    "    self.encoder = Encoder(num_inputs)\n",
    "    self.predictor = Predictor(num_outputs)\n",
    "    self.joiner = Joiner(num_outputs)\n",
    "\n",
    "    if torch.cuda.is_available(): self.device = \"cuda:0\"\n",
    "    else: self.device = \"cpu\"\n",
    "    self.to(self.device)\n",
    "\n",
    "  def compute_forward_prob(self, joiner_out, T, U, y):\n",
    "    \"\"\"\n",
    "    @joiner_out: tensor of shape (B, T_max, U_max+1, num_labels)\n",
    "    @T: list of input lengths\n",
    "    @U: list of output lengths \n",
    "    @y: label tensor (B, U_max+1)\n",
    "\n",
    "    DIRECTIONS: draw out a couple iterations of the nested for loop below\n",
    "    <15 min>\n",
    "    \"\"\"\n",
    "    B = joiner_out.shape[0]                                        #B = batch size??\n",
    "    T_max = joiner_out.shape[1]\n",
    "    U_max = joiner_out.shape[2] - 1\n",
    "    log_alpha = torch.zeros(B, T_max, U_max+1).to(model.device)\n",
    "    for t in range(T_max):\n",
    "      for u in range(U_max+1):\n",
    "          if u == 0:\n",
    "            if t == 0:\n",
    "              log_alpha[:, t, u] = 0.\n",
    "\n",
    "            else: #t > 0\n",
    "              log_alpha[:, t, u] = log_alpha[:, t-1, u] + joiner_out[:, t-1, 0, NULL_INDEX] \n",
    "                  \n",
    "          else: #u > 0\n",
    "            if t == 0:\n",
    "              log_alpha[:, t, u] = log_alpha[:, t,u-1] + torch.gather(joiner_out[:, t, u-1], dim=1, index=y[:,u-1].view(-1,1) ).reshape(-1)\n",
    "            \n",
    "            else: #t > 0\n",
    "              log_alpha[:, t, u] = torch.logsumexp(torch.stack([\n",
    "                  log_alpha[:, t-1, u] + joiner_out[:, t-1, u, NULL_INDEX],\n",
    "                  log_alpha[:, t, u-1] + torch.gather(joiner_out[:, t, u-1], dim=1, index=y[:,u-1].view(-1,1) ).reshape(-1)\n",
    "              ]), dim=0)\n",
    "    \n",
    "    log_probs = []\n",
    "    for b in range(B):\n",
    "      log_prob = log_alpha[b, T[b]-1, U[b]] + joiner_out[b, T[b]-1, U[b], NULL_INDEX]\n",
    "      log_probs.append(log_prob)\n",
    "    log_probs = torch.stack(log_probs) \n",
    "    return log_prob # history of logits??\n",
    "\n",
    "  def compute_loss(self, x, y, T, U):\n",
    "    \"\"\"\n",
    "    @x: input/training tensor\n",
    "    @y: label tensor\n",
    "    @T: list of the length of input sequences\n",
    "    @U: list of the length of output sequences\n",
    "    \"\"\"\n",
    "    encoder_out = self.encoder.forward(x)\n",
    "    predictor_out = self.predictor.forward(y)\n",
    "    joiner_out = self.joiner.forward(encoder_out.unsqueeze(2), predictor_out.unsqueeze(1)).log_softmax(3)\n",
    "    loss = -self.compute_forward_prob(joiner_out, T, U, y).mean()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IK0c2S2xaARd"
   },
   "source": [
    "Let's first verify that the forward algorithm actually correctly computes the sum (in log space, the [logsumexp](https://lorenlugosch.github.io/posts/2020/06/logsumexp/)) of all possible alignments, using a short input/output pair for which computing all possible alignments is feasible.\n",
    "\n",
    "<img src=\"https://lorenlugosch.github.io/images/transducer/cat-align-1.png\" width=\"25%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RWtkoXH6U8Pm"
   },
   "outputs": [],
   "source": [
    "def compute_single_alignment_prob(self, encoder_out, predictor_out, T, U, z, y):\n",
    "    \"\"\"\n",
    "    Computes the probability of one alignment, z.\n",
    "    @encoder_out: Transducer's self.encoder\n",
    "    @predictor_out: Transducer's self.predictor\n",
    "    @T: list of the length of input sequences\n",
    "    @U: list of the length of output sequences\n",
    "    @z: \n",
    "    @y: label tensor\n",
    "\n",
    "    DIRECTIONS: write a brief description of the argument 'z' above\n",
    "                complete the variables for t_indices and u_indices\n",
    "    <5 min>\n",
    "    \"\"\"\n",
    "    t = 0; u = 0\n",
    "    t_u_indices = []\n",
    "    y_expanded = []\n",
    "    for step in z:\n",
    "      t_u_indices.append((t,u))\n",
    "      if step == 0: # right (null)\n",
    "        y_expanded.append(NULL_INDEX)\n",
    "        t += 1\n",
    "      if step == 1: # down (label)\n",
    "        y_expanded.append(y[u])\n",
    "        u += 1\n",
    "    t_u_indices.append((T-1,U))\n",
    "    y_expanded.append(NULL_INDEX)\n",
    "\n",
    "    t_indices = None\n",
    "    u_indices = None\n",
    "    encoder_out_expanded = encoder_out[t_indices]\n",
    "    predictor_out_expanded = predictor_out[u_indices]\n",
    "    joiner_out = self.joiner.forward(encoder_out_expanded, predictor_out_expanded).log_softmax(1)\n",
    "    logprob = -torch.nn.functional.nll_loss(input=joiner_out, target=torch.tensor(y_expanded).long().to(self.device), reduction=\"sum\")\n",
    "    return logprob\n",
    "\n",
    "Transducer.compute_single_alignment_prob = compute_single_alignment_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e8xzM0dZfea9",
    "outputId": "241648b8-5484-4220-d6a5-469bb05f5253"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss computed by enumerating all possible alignments:  tensor(21.0155)\n",
      "Loss computed using the forward algorithm:  tensor(21.0155, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Generate example inputs/outputs\n",
    "num_outputs = len(string.ascii_uppercase) + 1 # [null, A, B, ... Z]\n",
    "model = Transducer(1, num_outputs)\n",
    "y_letters = \"CAT\"\n",
    "y = torch.tensor([string.ascii_uppercase.index(l) + 1 for l in y_letters]).unsqueeze(0).to(model.device)\n",
    "T = torch.tensor([4]); U = torch.tensor([len(y_letters)]); B = 1\n",
    "\n",
    "encoder_out = torch.randn(B, T, joiner_dim).to(model.device)\n",
    "predictor_out = torch.randn(B, U+1, joiner_dim).to(model.device)\n",
    "joiner_out = model.joiner.forward(encoder_out.unsqueeze(2), predictor_out.unsqueeze(1)).log_softmax(3)\n",
    "\n",
    "#######################################################\n",
    "# Compute loss by enumerating all possible alignments #\n",
    "#######################################################\n",
    "all_permutations = list(itertools.permutations([0]*(T-1) + [1]*U))\n",
    "all_distinct_permutations = list(Counter(all_permutations).keys())\n",
    "alignment_probs = []\n",
    "for z in all_distinct_permutations:\n",
    "  alignment_prob = model.compute_single_alignment_prob(encoder_out[0], predictor_out[0], T.item(), U.item(), z, y[0])\n",
    "  alignment_probs.append(alignment_prob)\n",
    "loss_enumerate = -torch.tensor(alignment_probs).logsumexp(0)\n",
    "\n",
    "#######################################################\n",
    "# Compute loss using the forward algorithm            #\n",
    "#######################################################\n",
    "loss_forward = -model.compute_forward_prob(joiner_out, T, U, y)\n",
    "\n",
    "print(\"Loss computed by enumerating all possible alignments: \", loss_enumerate)\n",
    "print(\"Loss computed using the forward algorithm: \", loss_forward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WSBAwQONf3z9"
   },
   "source": [
    "Now let's add the greedy search algorithm for predicting an output sequence.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "(Note that I've assumed we're using RNNs for the predictor here. You would have to modify this code a bit if you want to use convolutions/self-attention instead.) \n",
    "<br/><br/>\n",
    "<img src=\"https://lorenlugosch.github.io/images/transducer/greedy-search.png\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V0xeyb7Jf18_"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DIRECTIONS: YOU DO NOT NEED TO IMPLEMENT BEAM SEARCH\n",
    "Here is an *opportunity* to create a beam-search. While the code\n",
    "for a greedy search is here, we can improve this algorithmically! So, you\n",
    "use the greedy search code here to ensure that things are working\n",
    "\n",
    "<might take a while>\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "def greedy_search(self, x, T):\n",
    "  y_batch = []\n",
    "  B = len(x)\n",
    "  encoder_out = self.encoder.forward(x)\n",
    "  U_max = 200\n",
    "  for b in range(B):\n",
    "    t = 0; u = 0; y = [self.predictor.start_symbol]; predictor_state = self.predictor.initial_state.unsqueeze(0)\n",
    "    while t < T[b] and u < U_max:\n",
    "      predictor_input = torch.tensor([ y[-1] ]).to(x.device)\n",
    "      g_u, predictor_state = self.predictor.forward_one_step(predictor_input, predictor_state)\n",
    "      f_t = encoder_out[b, t]\n",
    "      h_t_u = self.joiner.forward(f_t, g_u)\n",
    "      argmax = h_t_u.max(-1)[1].item()\n",
    "      if argmax == NULL_INDEX:\n",
    "        t += 1\n",
    "      else: # argmax == a label\n",
    "        u += 1\n",
    "        y.append(argmax)\n",
    "    y_batch.append(y[1:]) # remove start symbol\n",
    "  return y_batch\n",
    "\n",
    "Transducer.greedy_search = greedy_search\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qhUQMJ-23f2y",
    "outputId": "85b406cd-8cfd-4c8c-817b-0cb851531f56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting speechbrain\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/a0/16623a27ceddd5c96dbf1f0ce3393c5266a8276a805f1a111382f8a46efb/speechbrain-0.5.5-py3-none-any.whl (350kB)\n",
      "\u001b[K     |████████████████████████████████| 358kB 17.7MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting huggingface-hub\n",
      "  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from speechbrain) (1.19.5)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from speechbrain) (1.4.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from speechbrain) (4.41.1)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from speechbrain) (1.0.1)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from speechbrain) (1.8.1+cu101)\n",
      "Collecting sentencepiece\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2MB 52.9MB/s \n",
      "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from speechbrain) (20.9)\n",
      "Collecting torchaudio\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/aa/55/01ad9244bcd595e39cea5ce30726a7fe02fd963d07daeb136bfe7e23f0a5/torchaudio-0.8.1-cp37-cp37m-manylinux1_x86_64.whl (1.9MB)\n",
      "\u001b[K     |████████████████████████████████| 1.9MB 50.6MB/s \n",
      "\u001b[?25hCollecting hyperpyyaml\n",
      "  Downloading https://files.pythonhosted.org/packages/17/e2/63e6353151cb4359f66e93f52152d7d60c1b32c87f5b2e2e58419d2a3711/HyperPyYAML-1.0.0-py3-none-any.whl\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->speechbrain) (3.0.12)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->speechbrain) (2.23.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->speechbrain) (3.10.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->speechbrain) (3.7.4.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->speechbrain) (2.4.7)\n",
      "Collecting pyyaml>=5.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/a5/393c087efdc78091afa2af9f1378762f9821c9c1d7a22c5753fb5ac5f97a/PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636kB)\n",
      "\u001b[K     |████████████████████████████████| 645kB 49.0MB/s \n",
      "\u001b[?25hCollecting ruamel.yaml>=0.15\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/4e/c3105bbbbc662f6a671a505f00ec771e93b5254f09fbb06002af9087071a/ruamel.yaml-0.17.4-py3-none-any.whl (101kB)\n",
      "\u001b[K     |████████████████████████████████| 102kB 13.3MB/s \n",
      "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub->speechbrain) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub->speechbrain) (2020.12.5)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub->speechbrain) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub->speechbrain) (3.0.4)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->huggingface-hub->speechbrain) (3.4.1)\n",
      "Collecting ruamel.yaml.clib>=0.1.2; platform_python_implementation == \"CPython\" and python_version < \"3.10\"\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/6e/f652c56bbb2c3d3fca252ffc7c0358597f57a1bbdf484dac683054950c63/ruamel.yaml.clib-0.2.2-cp37-cp37m-manylinux1_x86_64.whl (547kB)\n",
      "\u001b[K     |████████████████████████████████| 552kB 57.2MB/s \n",
      "\u001b[?25hInstalling collected packages: huggingface-hub, sentencepiece, torchaudio, pyyaml, ruamel.yaml.clib, ruamel.yaml, hyperpyyaml, speechbrain\n",
      "  Found existing installation: PyYAML 3.13\n",
      "    Uninstalling PyYAML-3.13:\n",
      "      Successfully uninstalled PyYAML-3.13\n",
      "Successfully installed huggingface-hub-0.0.8 hyperpyyaml-1.0.0 pyyaml-5.4.1 ruamel.yaml-0.17.4 ruamel.yaml.clib-0.2.2 sentencepiece-0.1.95 speechbrain-0.5.5 torchaudio-0.8.1\n"
     ]
    }
   ],
   "source": [
    "!pip install speechbrain\n",
    "from speechbrain.nnet.loss.transducer_loss import TransducerLoss\n",
    "transducer_loss = TransducerLoss(0)\n",
    "\n",
    "def compute_loss(self, x, y, T, U):\n",
    "    encoder_out = self.encoder.forward(x)\n",
    "    predictor_out = self.predictor.forward(y)\n",
    "    joiner_out = self.joiner.forward(encoder_out.unsqueeze(2), predictor_out.unsqueeze(1)).log_softmax(3)\n",
    "    #loss = -self.compute_forward_prob(joiner_out, T, U, y).mean()\n",
    "    T = T.to(joiner_out.device)\n",
    "    U = U.to(joiner_out.device)\n",
    "    loss = transducer_loss(joiner_out, y, T, U) #, blank_index=NULL_INDEX, reduction=\"mean\")\n",
    "    return loss\n",
    "\n",
    "Transducer.compute_loss = compute_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ff9raB0jVGzN"
   },
   "source": [
    "# Some utilities\n",
    "\n",
    "Here we will add a bit of boilerplate code for training and loading data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5b17OQm4WdVy",
    "outputId": "25498f94-9543-40f8-dd1e-fbfd7857debf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('\"Wll, Prnc, s Gn nd Lcc r nw jst fmly stts f th',\n",
       " '\"Well, Prince, so Genoa and Lucca are now just family estates of the')"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TextDataset(torch.utils.data.Dataset):\n",
    "  def __init__(self, lines, batch_size):\n",
    "    \"\"\"\n",
    "    @lines: list of strings\n",
    "    \"\"\"\n",
    "    lines = list(filter((\"\\n\").__ne__, lines))\n",
    "\n",
    "    self.lines = lines \n",
    "    collate = Collate()\n",
    "    self.loader = torch.utils.data.DataLoader(self, batch_size=batch_size, num_workers=1, shuffle=True, collate_fn=collate)\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.lines)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    line = self.lines[idx].replace(\"\\n\", \"\")\n",
    "    line = unidecode.unidecode(line) # remove special characters\n",
    "    x = \"\".join(c for c in line if c not in \"AEIOUaeiou\") # remove vowels from input\n",
    "    y = line\n",
    "    return (x,y)\n",
    "\n",
    "def encode_string(s):\n",
    "  \"\"\"\n",
    "  @s: string\n",
    "  \"\"\"\n",
    "  for c in s:\n",
    "    if c not in string.printable:\n",
    "      print(s)\n",
    "  return [string.printable.index(c) + 1 for c in s]\n",
    "\n",
    "def decode_labels(l):\n",
    "  \"\"\"\n",
    "  @l: list of labels\n",
    "  \"\"\"\n",
    "  return \"\".join([string.printable[c - 1] for c in l])\n",
    "\n",
    "\n",
    "class Collate:\n",
    "  def __call__(self, batch):\n",
    "    \"\"\"\n",
    "    Returns a minibatch of strings, encoded as labels and padded to have the same length.\n",
    "    @batch: list of tuples (input string, output string)\n",
    "\n",
    "    DIRECTIONS: after obtaining results from training on the default text, train on your second training text \n",
    "    <10 min>\n",
    "    \"\"\"\n",
    "    x = []; y = []\n",
    "    batch_size = len(batch)\n",
    "    for index in range(batch_size):\n",
    "      x_,y_ = batch[index]\n",
    "      x.append(encode_string(x_))\n",
    "      y.append(encode_string(y_))\n",
    "\n",
    "    # pad all sequences to have same length\n",
    "    T = [len(x_) for x_ in x]\n",
    "    U = [len(y_) for y_ in y]\n",
    "    T_max = max(T)\n",
    "    U_max = max(U)\n",
    "    for index in range(batch_size):\n",
    "      x[index] += [NULL_INDEX] * (T_max - len(x[index]))\n",
    "      x[index] = torch.tensor(x[index])\n",
    "      y[index] += [NULL_INDEX] * (U_max - len(y[index]))\n",
    "      y[index] = torch.tensor(y[index])\n",
    "\n",
    "    # stack into single tensor\n",
    "    x = torch.stack(x)\n",
    "    y = torch.stack(y)\n",
    "    T = torch.tensor(T)\n",
    "    U = torch.tensor(U)\n",
    "\n",
    "    return (x,y,T,U)\n",
    "\n",
    "with open(\"war_and_peace.txt\", \"r\") as f:\n",
    "  lines = f.readlines()\n",
    "\n",
    "end = round(0.9 * len(lines))\n",
    "train_lines = lines[:end]\n",
    "test_lines = lines[end:]\n",
    "train_set = TextDataset(train_lines, batch_size=64) #8)\n",
    "test_set = TextDataset(test_lines, batch_size=64) #8)\n",
    "train_set.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gaZEQYzfFEQ0"
   },
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "  def __init__(self, model, lr):\n",
    "    self.model = model\n",
    "    self.lr = lr\n",
    "    self.optimizer = torch.optim.Adam(model.parameters(), lr=self.lr)\n",
    "  \n",
    "  def train(self, dataset, print_interval = 20):\n",
    "    train_loss = 0\n",
    "    num_samples = 0\n",
    "    self.model.train()\n",
    "    pbar = tqdm(dataset.loader)\n",
    "    for idx, batch in enumerate(pbar):\n",
    "      x,y,T,U = batch\n",
    "      x = x.to(self.model.device); y = y.to(self.model.device)\n",
    "      batch_size = len(x)\n",
    "      num_samples += batch_size\n",
    "      loss = self.model.compute_loss(x,y,T,U)\n",
    "      self.optimizer.zero_grad()\n",
    "      pbar.set_description(\"%.2f\" % loss.item())\n",
    "      loss.backward()\n",
    "      self.optimizer.step()\n",
    "      train_loss += loss.item() * batch_size\n",
    "      if idx % print_interval == 0:\n",
    "        self.model.eval()\n",
    "        guesses = self.model.greedy_search(x,T)\n",
    "        self.model.train()\n",
    "        print(\"\\n\")\n",
    "        for b in range(2):\n",
    "          print(\"input:\", decode_labels(x[b,:T[b]]))\n",
    "          print(\"guess:\", decode_labels(guesses[b]))\n",
    "          print(\"truth:\", decode_labels(y[b,:U[b]]))\n",
    "          print(\"\")\n",
    "    train_loss /= num_samples\n",
    "    return train_loss\n",
    "\n",
    "  def test(self, dataset, print_interval=1):\n",
    "    test_loss = 0\n",
    "    num_samples = 0\n",
    "    self.model.eval()\n",
    "    pbar = tqdm(dataset.loader)\n",
    "    for idx, batch in enumerate(pbar):\n",
    "      x,y,T,U = batch\n",
    "      x = x.to(self.model.device); y = y.to(self.model.device)\n",
    "      batch_size = len(x)\n",
    "      num_samples += batch_size\n",
    "      loss = self.model.compute_loss(x,y,T,U)\n",
    "      pbar.set_description(\"%.2f\" % loss.item())\n",
    "      test_loss += loss.item() * batch_size\n",
    "      if idx % print_interval == 0:\n",
    "        print(\"\\n\")\n",
    "        print(\"input:\", decode_labels(x[0,:T[0]]))\n",
    "        print(\"guess:\", decode_labels(self.model.greedy_search(x,T)[0]))\n",
    "        print(\"truth:\", decode_labels(y[0,:U[0]]))\n",
    "        print(\"\")\n",
    "    test_loss /= num_samples\n",
    "    return test_loss\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q4PupgBKWe6p"
   },
   "source": [
    "# Training the model\n",
    "\n",
    "Now we will train a model. This will generate some output sequences every 20 batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1TSrbH9xGPEC"
   },
   "outputs": [],
   "source": [
    "num_chars = len(string.printable)\n",
    "model = Transducer(num_inputs=num_chars+1, num_outputs=num_chars+1)\n",
    "trainer = Trainer(model=model, lr=0.0003)\n",
    "\n",
    "num_epochs = 1\n",
    "train_losses=[]\n",
    "test_losses=[]\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = trainer.train(train_set)\n",
    "    test_loss = trainer.test(test_set)\n",
    "    train_losses.append(train_loss)\n",
    "    test_losses.append(test_loss)\n",
    "    print(\"Epoch %d: train loss = %f, test loss = %f\" % (epoch, train_loss, test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qRahAWPoubyu"
   },
   "outputs": [],
   "source": [
    "print(train_losses)\n",
    "print(test_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rLQKw4kmFj3S"
   },
   "source": [
    "Let's test the model on a new sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zhH5lYdyEazJ",
    "outputId": "d7938f4f-0f91-477c-8d87-03163c2ed7bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: Mst ppl hv lttl dffclty rdng ths sntnc\n",
      "truth: Most people have little difficulty reading this sentence\n",
      "guess: Mos pepel have litle dificulty riding thes sentenc\n",
      "\n",
      "NLL of truth: tensor(0.1161, device='cuda:0', grad_fn=<TransducerBackward>)\n",
      "NLL of guess: tensor(1.4692, device='cuda:0', grad_fn=<TransducerBackward>)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DIRECTIONS: Experiment with different test outputs. What are some things to keep in mind when changing the test outputs?\n",
    "<5 min>\n",
    "\"\"\"\n",
    "\n",
    "test_output = \"Most people have little difficulty reading this sentence\"\n",
    "test_input = \"\".join(c for c in test_output if c not in \"AEIOUaeiou\")\n",
    "print(\"input: \" + test_input)\n",
    "x = torch.tensor(encode_string(test_input)).unsqueeze(0).to(model.device)\n",
    "y = torch.tensor(encode_string(test_output)).unsqueeze(0).to(model.device)\n",
    "T = torch.tensor([x.shape[1]]).to(model.device)\n",
    "U = torch.tensor([y.shape[1]]).to(model.device)\n",
    "guess = model.greedy_search(x,T)[0]\n",
    "print(\"truth: \" + test_output)\n",
    "print(\"guess: \" + decode_labels(guess))\n",
    "print(\"\")\n",
    "y_guess = torch.tensor(guess).unsqueeze(0).to(model.device)\n",
    "U_guess = torch.tensor(len(guess)).unsqueeze(0).to(model.device)\n",
    "\n",
    "print(\"NLL of truth: \" + str(model.compute_loss(x, y, T, U)))\n",
    "print(\"NLL of guess: \" + str(model.compute_loss(x, y_guess, T, U_guess)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ET__-ItZD8eA"
   },
   "source": [
    "Observe that the negative log-likelihood of the guess is actually worse than that of the true label sequence (AKA, a \"[search error](https://www.aclweb.org/anthology/D19-1331.pdf)\"). This suggests that we could get better results using a beam search instead of the greedy search."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
