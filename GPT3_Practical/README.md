# GPT3 Practical

Github Link : https://github.com/umesh-gattem/LING-L645/tree/GPT3-practical/GPT3_Practical

### TASK 1 : 

1. Study the Impact of GPT3 Parameters on Classification Accuracy  
   * Dataset used : Twitter Sentiment Classification
   * Metrics : Plot accuracy Scores by varying parameters
2. Parameters are
   * Engine Type  : Model to be used. Options are Davinci, Babbage, Ada and Curie.
   * Temperature : Amount of randomness to be introduced in the predictions of the
       model Setting a higher value of temperature would be useful for creative 
       applications whereas a lower value will be suitable for well defined answers.
   * Token Length : Maximum length of number of tokens accepted by the prompt.

### TASK 2 :

1. Given an abstract of a research paper, determine the number of shots required to generate a title as similar as possible to the actual title
2. Feed examples to GPT-3 through the API provided by OpenAI
3. Use BLEU Score to compare the predicted title with the ground truth
4. Comment on your learnings


### TASK 3 : (TAKE AWAY HOME)

1. In this task we will compare the performance of GPT3 with any fine-tuning Language Model. 
2. For our ease, let’s take the reference of our last practical Seq_to_Seq translation use case.
3. Let’s solve the problem using the Bahdinau_Attention fine-tuning model and solve the same using the GPT3 and compare the metrics and results.




